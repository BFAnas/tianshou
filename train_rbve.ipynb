{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "from tianshou.data import Collector, Batch, to_torch\n",
    "from tianshou.data.types import RolloutBatchProtocol\n",
    "from tianshou.data.buffer.vecbuf import VectorReplayBuffer, ReplayBuffer\n",
    "from tianshou.env import SubprocVectorEnv\n",
    "from tianshou.policy import RBVEPolicy, BasePolicy\n",
    "from tianshou.utils.net.common import Net\n",
    "from tianshou.utils.net.continuous import ActorProb, Critic\n",
    "from examples.offline.utils import load_buffer_d4rl\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tianshou.utils import TensorboardLogger\n",
    "from tianshou.trainer import OffpolicyTrainer\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_value(value):\n",
    "    # Convert simple types (int, float, bool, None)\n",
    "    if value.isdigit():\n",
    "        return int(value)\n",
    "    elif re.match(r'^\\d+\\.\\d+$', value):\n",
    "        return float(value)\n",
    "    elif value == \"True\":\n",
    "        return True\n",
    "    elif value == \"False\":\n",
    "        return False\n",
    "    elif value == \"None\":\n",
    "        return None\n",
    "    elif value.startswith(\"[\") and value.endswith(\"]\"):\n",
    "        # Convert the list items\n",
    "        items = re.split(r',(?=[^\\]]*(?:\\[|$))', value[1:-1])\n",
    "        return [parse_value(item.strip()) for item in items]\n",
    "    elif value.startswith(\"(\") and value.endswith(\")\"):\n",
    "        # Convert the tuple items\n",
    "        items = re.split(r',(?=[^\\)]*(?:\\(|$))', value[1:-1])\n",
    "        # Special case for single-item tuple\n",
    "        if len(items) == 2 and items[0].strip() != '':\n",
    "            return (parse_value(items[0].strip()),)\n",
    "        return tuple(parse_value(item.strip()) for item in items)\n",
    "    elif value.startswith(\"'\") and value.endswith(\"'\"):\n",
    "        return value[1:-1]\n",
    "    # Else, return the value as-is\n",
    "    return value\n",
    "\n",
    "def get_args(event_file, device):\n",
    "    ea = EventAccumulator(event_file)\n",
    "    ea.Reload()  # Load the file\n",
    "    # Get the text data\n",
    "    texts = ea.Tags()[\"tensors\"]\n",
    "    # Extract the actual text content\n",
    "    text_data = {}\n",
    "    for tag in texts:\n",
    "        events = ea.Tensors(tag)\n",
    "        for event in events:\n",
    "            # You can extract the wall_time and step if needed\n",
    "            # wall_time, step, value = event.wall_time, event.step, event.text\n",
    "            text_data[tag] = event.tensor_proto.string_val\n",
    "    data = text_data['args/text_summary'][0]\n",
    "    # Convert bytes to string\n",
    "    data_str = data.decode('utf-8')\n",
    "    # Remove the \"Namespace(\" prefix and the trailing \")\"\n",
    "    data_str = data_str[len(\"Namespace(\"):-1]\n",
    "    # Split into key-value pairs\n",
    "    key_values = re.split(r',(?=\\s\\w+=)', data_str)\n",
    "    # Parse each key-value pair\n",
    "    args_dict = {}\n",
    "    for kv in key_values:\n",
    "        key, value = kv.split('=', 1)\n",
    "        key = key.strip()\n",
    "        args_dict[key] = parse_value(value)\n",
    "    args = SimpleNamespace(**args_dict)\n",
    "    try:\n",
    "        env = gym.make(args.task)\n",
    "        target_entropy = -np.prod(env.action_space.shape)\n",
    "        log_alpha = torch.zeros(1, requires_grad=True, device=device)\n",
    "        alpha_optim = torch.optim.Adam([log_alpha], lr=args.alpha_lr)\n",
    "        args.alpha = (target_entropy, log_alpha, alpha_optim)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(task='HalfCheetah-v2',\n",
       "          seed=0,\n",
       "          expert_data_task='halfcheetah-medium-v2',\n",
       "          buffer_size=1000000,\n",
       "          hidden_sizes=[256, 256, 256],\n",
       "          actor_lr=0.0001,\n",
       "          critic_lr=0.0003,\n",
       "          alpha=(-6,\n",
       "                 tensor([0.], device='cuda:3', requires_grad=True),\n",
       "                 Adam (\n",
       "                 Parameter Group 0\n",
       "                     amsgrad: False\n",
       "                     betas: (0.9, 0.999)\n",
       "                     capturable: False\n",
       "                     differentiable: False\n",
       "                     eps: 1e-08\n",
       "                     foreach: None\n",
       "                     fused: None\n",
       "                     lr: 0.0001\n",
       "                     maximize: False\n",
       "                     weight_decay: 0\n",
       "                 )),\n",
       "          device='cuda',\n",
       "          requires_grad='True), Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    lr: 0.0001\\n    maximize: False\\n    weight_decay: 0\\n))',\n",
       "          auto_alpha=True,\n",
       "          alpha_lr=0.0001,\n",
       "          cql_alpha_lr=0.0003,\n",
       "          start_timesteps=10000,\n",
       "          epoch=200,\n",
       "          step_per_epoch=5000,\n",
       "          batch_size=256,\n",
       "          norm_layer=True,\n",
       "          tau=0.005,\n",
       "          temperature=1.0,\n",
       "          cql_weight=5.0,\n",
       "          with_lagrange=False,\n",
       "          calibrated=False,\n",
       "          lagrange_threshold=10.0,\n",
       "          gamma=0.99,\n",
       "          eval_freq=1,\n",
       "          test_num=10,\n",
       "          logdir='log',\n",
       "          render=0.02857142857142857,\n",
       "          resume_path=None,\n",
       "          resume_id=None,\n",
       "          logger='tensorboard',\n",
       "          wandb_project='offline_d4rl.benchmark',\n",
       "          watch=False,\n",
       "          state_shape=(17,),\n",
       "          action_shape=(6,),\n",
       "          max_action=1.0,\n",
       "          state_dim=17,\n",
       "          action_dim=6,\n",
       "          algo_name='cql')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = \"/data/user/R901105/dev/log/HalfCheetah-v2/cql/0/240426-213255\"\n",
    "files = os.listdir(log_path)\n",
    "event_file = [f for f in files if f.startswith('event')][0]\n",
    "full_path = os.path.join(log_path, event_file)\n",
    "args = get_args(full_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
